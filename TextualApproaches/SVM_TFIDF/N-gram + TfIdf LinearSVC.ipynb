{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cfe932",
   "metadata": {},
   "source": [
    "# Preprocess data: lemmatize and remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b44082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_group(name):\n",
    "    d = {'Arkhangelskie': 'Архангельские',\n",
    "         'Desninskie': 'Верхне-Деснинские',\n",
    "         'Donskie': 'Донские',\n",
    "         'Kostromskie': 'Костромские',\n",
    "         'Mezhzonalnie': 'Межзональная группа Б',\n",
    "         'Novgorodskie': 'Новгородские',\n",
    "         'Povolzkie': 'Владимирско-Поволжские',\n",
    "         'Pskovskie': 'Псковские',\n",
    "         'Ryazanskie': 'Рязанские',\n",
    "         'Seligerskie': 'Селигеро-Торжковские'}\n",
    "    return d[name]\n",
    "\n",
    "df = pd.read_excel('manifest_balanced.xlsx')\n",
    "df['variant_rus'] = df['Variant'].apply(rename_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b360e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = re.sub('-', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964794fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('', '', punct))\n",
    "        doc = Doc(text)\n",
    "        doc.segment(segmenter)\n",
    "        doc.tag_morph(morph_tagger)\n",
    "        for token in doc.tokens:\n",
    "            token.lemmatize(morph_vocab)\n",
    "        lemmas = []\n",
    "        for token in doc.tokens:\n",
    "            if token.pos != 'PUNCT' and token.text != '=':\n",
    "                lemmas.append(token.lemma)\n",
    "        return ' '.join(lemmas)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4323bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = df.progress_apply(lambda x: preprocessing(x['text']), axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8ebad",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e2470",
   "metadata": {},
   "source": [
    "Split on train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "for variant in list(df['Variant'].unique()):\n",
    "    train_df, valid_test_df = train_test_split(df[df['Variant']==variant], test_size=0.3, random_state=55)\n",
    "    valid_df, test_df = train_test_split(valid_test_df, test_size=0.5, random_state=55)\n",
    "    train = pd.concat([train, train_df])\n",
    "    valid = pd.concat([valid, valid_df])\n",
    "    test = pd.concat([test, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001798e",
   "metadata": {},
   "source": [
    "# CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                   ('ovr', LinearSVC(loss='squared_hinge', max_iter=100000, multi_class='ovr'))\n",
    "                    ])\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 3), (2, 4), (2, 5), (2, 6)],\n",
    "    'tfidf__analyzer': ['char'],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'tfidf__max_df': [0.75, 0.85, 1.0],\n",
    "    'ovr__C': [0.1, 1, 10],\n",
    "    'ovr__tol': [1e-5, 1e-4, 1e-3]\n",
    "    \n",
    "}\n",
    "\n",
    "train_y = train['Variant'].values.reshape(-1,1)\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=parameters, scoring='f1_macro', verbose=3)\n",
    "gs.fit(train['lemmas'], train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe76882",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_char = pd.concat([pd.DataFrame(gs.cv_results_[\"params\"]), \n",
    "                            pd.DataFrame(gs.cv_results_[\"mean_test_score\"], \n",
    "                                         columns=[\"f1_macro\"])],axis=1)\n",
    "gs_result_char.to_excel('GridSearchCV_LinearSVM_char.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline([('tfidf', TfidfVectorizer(analyzer='char', max_df=0.85, ngram_range=(1,6))),\n",
    "                   ('ovr', LinearSVC(loss='squared_hinge', max_iter=100000, multi_class='ovr', C=1))])\n",
    "\n",
    "train_y = train['Variant'].values.reshape(-1,1)\n",
    "pipeline.fit(train['lemmas'], train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['Variant'], pipeline.predict(test['lemmas'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abacc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(test['Variant'], pipeline.predict(test['lemmas']),\n",
    "                               xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775fac9",
   "metadata": {},
   "source": [
    "# WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2effb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                   ('ovr', LinearSVC(loss='squared_hinge', max_iter=100000, multi_class='ovr')),\n",
    "                    ])\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 3), (2, 4), (2, 5), (2, 6)],\n",
    "    'tfidf__analyzer': ['word'],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'tfidf__max_df': [0.75, 0.85, 1.0],\n",
    "    'ovr__C': [0.1, 1, 10],\n",
    "    'ovr__tol': [1e-5, 1e-4, 1e-3]\n",
    "    \n",
    "}\n",
    "\n",
    "train_y = train['Variant'].values.reshape(-1,1)\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=parameters, scoring='f1_macro', verbose=3)\n",
    "gs.fit(train['lemmas'], train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_char = pd.concat([pd.DataFrame(gs.cv_results_[\"params\"]), \n",
    "                            pd.DataFrame(gs.cv_results_[\"mean_test_score\"], \n",
    "                                         columns=[\"f1_macro\"])],axis=1)\n",
    "gs_result_char.to_excel('GridSearchCV_LinearSVM_word.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline([('tfidf', TfidfVectorizer(analyzer='word', max_df=0.75, ngram_range=(1,2))),\n",
    "                   ('ovr', LinearSVC(loss='squared_hinge', max_iter=100000, multi_class='ovr', C=1))])\n",
    "\n",
    "train_y = train['Variant'].values.reshape(-1,1)\n",
    "pipeline.fit(train['lemmas'], train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b587270",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['Variant'], pipeline.predict(test['lemmas'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54860e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(test['Variant'], pipeline.predict(test['lemmas']),\n",
    "                               xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55de83",
   "metadata": {},
   "source": [
    "# CHAR + WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tfidf = TfidfVectorizer(analyzer='char')\n",
    "word_tfidf = TfidfVectorizer(analyzer='word')\n",
    "tfidf = FeatureUnion([('char', char_tfidf), ('word', word_tfidf)])\n",
    "pipeline = Pipeline([('tfidf', tfidf),\n",
    "                     ('ovr', LinearSVC(loss='squared_hinge', max_iter=100000, multi_class='ovr'))])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__char__ngram_range': [(2, 3), (2, 4), (2, 5), (2, 6)],\n",
    "    'tfidf__word__ngram_range': [(1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 3)],\n",
    "    'tfidf__char__max_df': [0.75, 0.85, 1.0],\n",
    "    'tfidf__word__max_df': [0.75, 0.85, 1.0],\n",
    "    'ovr__C': [1],\n",
    "    'ovr__tol': [1e-5]\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "train_y = train['Variant'].values.reshape(-1,1)\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=parameters, scoring='f1_macro', verbose=3)\n",
    "gs.fit(train['lemmas'], train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e048c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_result_char = pd.concat([pd.DataFrame(gs.cv_results_[\"params\"]), \n",
    "                            pd.DataFrame(gs.cv_results_[\"mean_test_score\"], \n",
    "                                         columns=[\"f1_macro\"])],axis=1)\n",
    "gs_result_char.to_excel('GridSearchCV_LinearSVM_char_word.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb194544",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tfidf = TfidfVectorizer(analyzer='char', max_df=0.85, ngram_range=(2,5))\n",
    "word_tfidf = TfidfVectorizer(analyzer='word', max_df=0.75, ngram_range=(1,3))\n",
    "tfidf = FeatureUnion([('char', char_tfidf), ('word', word_tfidf)])\n",
    "pipeline = Pipeline([('tfidf', tfidf), \n",
    "                     ('ovr', LinearSVC(loss='squared_hinge', max_iter=100000, multi_class='ovr'))])\n",
    "train_y = train['Variant'].values.reshape(-1,1)\n",
    "pipeline.fit(train['lemmas'], train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff57a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['Variant'], pipeline.predict(test['lemmas'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = ['Архангельские', 'Верхне-Деснинские', 'Донские', 'Костромские', 'Межзональная группа Б', \n",
    "        'Новгородские', 'Владимирско-Поволжские', 'Псковские', 'Рязанские', 'Селигеро-Торжковские']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f98089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "disp = ConfusionMatrixDisplay.from_predictions(test['Variant'], pipeline.predict(test['lemmas']),\n",
    "                                        display_labels = labs, xticks_rotation='vertical')\n",
    "disp = disp.plot(cmap=plt.cm.binary,values_format='g',xticks_rotation='vertical')\n",
    "plt.show()\n",
    "plt.savefig('heatmap_svm.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('heatmap_svm.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec88d52",
   "metadata": {},
   "source": [
    "# Get coefficients for each n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b74b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_coefficients = pipeline['ovr'].coef_\n",
    "feature_coefficients[0]\n",
    "\n",
    "coeff_list = pd.DataFrame(\n",
    "    {'feature': pipeline['tfidf'].get_feature_names_out(), \n",
    "     'Arkhangelskie': feature_coefficients[0], 'Desninskie': feature_coefficients[1], 'Donskie': feature_coefficients[2], \n",
    "     'Kostromskie': feature_coefficients[3], 'Mezhzonalnie': feature_coefficients[4], 'Novgorodskie': feature_coefficients[5],\n",
    "     'Povolzkie': feature_coefficients[6], 'Pskovskie': feature_coefficients[7], 'Ryazanskie': feature_coefficients[8], \n",
    "     'Seligerskie': feature_coefficients[9]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_list.to_excel('LinearSVM_char_word_coeffs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909027b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "corpus_index = [n for n in corpus]\n",
    "pd.DataFrame(X.todense(), index=corpus_index, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(random_state=42)\n",
    "ovr_classifier = OneVsRestClassifier(svm)\n",
    "ovr_classifier = ovr_classifier.fit(X_train, y_train)\n",
    "matrix = plot_confusion_matrix(ovr_classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7d237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
