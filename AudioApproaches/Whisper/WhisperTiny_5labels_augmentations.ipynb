{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dacc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import WhisperFeatureExtractor, set_seed, AutoModelForAudioClassification, TrainingArguments, Trainer, WhisperConfig, EarlyStoppingCallback\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
    "from audiomentations import AddGaussianNoise, TimeStretch, PitchShift, Gain\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "tqdm.pandas()\n",
    "set_seed(55)\n",
    "np.random.seed(55)\n",
    "random.seed(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa60503",
   "metadata": {},
   "source": [
    "# Read audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(path, sr=16000)\n",
    "        return audio\n",
    "    except:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fe45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25806/25806 [23:59<00:00, 17.93it/s]\n"
     ]
    }
   ],
   "source": [
    "manifest = pd.read_excel('manifest_balanced.xlsx')\n",
    "variants = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "manifest = manifest[manifest['Variant'].isin(variants)]\n",
    "manifest = manifest[['path', 'Variant', 'text', 'informant']]\n",
    "manifest['array'] = manifest['path'].progress_apply(read_audio)\n",
    "manifest['sampling_rate'] = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2391c",
   "metadata": {},
   "source": [
    "# Split on train, validation and test (speakers fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daeaf9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7767"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = manifest[['path', 'Variant', 'array', 'sampling_rate', 'informant']]\n",
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "variants = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "for variant in variants:\n",
    "    speaker_counts = manifest[manifest['Variant']==variant]['informant'].value_counts().to_dict()\n",
    "    total_records = len(manifest[manifest['Variant']==variant]['path'])\n",
    "    train_target = 0.7 * total_records\n",
    "    val_target = 0.165 * total_records\n",
    "    test_target = total_records - train_target - val_target\n",
    "    speaker_ids = list(speaker_counts.keys())\n",
    "    train_speakers, val_speakers, test_speakers = [], [], []\n",
    "    train_sum = val_sum = test_sum = 0\n",
    "    for speaker in speaker_ids:\n",
    "        count = speaker_counts[speaker]\n",
    "        if train_sum + count <= train_target:\n",
    "            train_speakers.append(speaker)\n",
    "            train_sum += count\n",
    "        elif val_sum + count <= val_target:\n",
    "            val_speakers.append(speaker)\n",
    "            val_sum += count\n",
    "        else:\n",
    "            test_speakers.append(speaker)\n",
    "            test_sum += count\n",
    "    train_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(train_speakers))]\n",
    "    valid_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(val_speakers))]\n",
    "    test_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(test_speakers))]\n",
    "    train = pd.concat([train, train_df])\n",
    "    valid = pd.concat([valid, valid_df])\n",
    "    test = pd.concat([test, test_df])\n",
    "train = train[train['array'].str.len()>0]\n",
    "valid = valid[valid['array'].str.len()>0]\n",
    "test = test[test['array'].str.len()>0]\n",
    "try:\n",
    "    del manifest\n",
    "    del train_df\n",
    "    del valid_df\n",
    "    del test_df\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367c65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'Variant': 'label'})\n",
    "valid = valid.rename(columns={'Variant': 'label'})\n",
    "test = test.rename(columns={'Variant': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e9e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'Arkhangelskie': 0, 'Novgorodskie': 1, 'Povolzkie': 2, 'Pskovskie': 3, 'Ryazanskie': 4}\n",
      "id2label: {0: 'Arkhangelskie', 1: 'Novgorodskie', 2: 'Povolzkie', 3: 'Pskovskie', 4: 'Ryazanskie'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "label2id = {label: index for index, label in enumerate(unique_labels)}\n",
    "id2label = {index: label for index, label in enumerate(unique_labels)}\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6926e",
   "metadata": {},
   "source": [
    "# Define types of augmentations and their parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae319b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1.0),\n",
    "                 PitchShift(min_semitones=-1.5, max_semitones=1.5, p=1.0),\n",
    "                 TimeStretch(min_rate=0.9, max_rate=1.1, p=1.0),\n",
    "                 Gain(min_gain_in_db=-6, max_gain_in_db=6, p=1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4354d6",
   "metadata": {},
   "source": [
    "# Applying augmentations to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214a762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_augmentations(array, path):\n",
    "    global augmentations\n",
    "    random.seed(len(path))\n",
    "    n_aug = random.choice([0, 1, 2])\n",
    "    aug_chain = random.sample(augmentations, n_aug)\n",
    "    for aug in aug_chain:\n",
    "        array = aug(samples=array, sample_rate=16000)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "683f31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17347/17347 [07:57<00:00, 36.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train['array'] = train.progress_apply(lambda row: apply_random_augmentations(row['array'], row['path']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d88271",
   "metadata": {},
   "source": [
    "# Configure the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a25032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0871118046bb47229ae30cdb77b7da2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/17347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5664a85aa52449fb14e750bee450c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c3610e514a43edace6855fb51804aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'test': Dataset.from_pandas(valid[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'valid': Dataset.from_pandas(test[['array', 'label']]).class_encode_column(\"label\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0f0f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].features[\"label\"].str2int('Arkhangelskie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12bb12c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25123"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del train\n",
    "    del valid\n",
    "    del test\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f1769",
   "metadata": {},
   "source": [
    "# Extract features from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fd36a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636f9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_features\"] = feature_extractor(batch[\"array\"], sampling_rate=16000, return_tensors='pt').input_features[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f21ec93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d3b43d733945529c1f5f1f18605ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd8e7e60f274891a97e2cd187c3ce33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111757b4b1e64cff8e8ff4047942b847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_audio = ds.map(prepare_dataset, remove_columns=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5278c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_audio = encoded_audio.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21a146b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(names=['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie'], id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_audio['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0526f2",
   "metadata": {},
   "source": [
    "# Define function for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a17bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84823b12",
   "metadata": {},
   "source": [
    "# Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ae8308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at openai/whisper-tiny and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhisperForAudioClassification(\n",
       "  (encoder): WhisperEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (embed_positions): Embedding(1500, 384)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x WhisperEncoderLayer(\n",
       "        (self_attn): WhisperSdpaAttention(\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projector): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (classifier): Linear(in_features=256, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(id2label)\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-tiny\", num_labels=num_labels, label2id=label2id, id2label=id2label)\n",
    "config.classifier_dropout = 0.3\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"openai/whisper-tiny\", config=config)\n",
    "device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b9a26",
   "metadata": {},
   "source": [
    "# Train classifier only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed57c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_encoder(model):\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74f871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_encoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d91bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "training_args_classifier = TrainingArguments(output_dir=f\"whisper-tiny-finetuned-rudialect-fixed-speakers-classifier-only-aug\",\n",
    "                                  eval_strategy =\"steps\",\n",
    "                                  save_strategy=\"steps\",\n",
    "                                  learning_rate=1e-4,\n",
    "                                  eval_steps=200,\n",
    "                                  save_steps=200,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  gradient_accumulation_steps=4,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  num_train_epochs=5,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  greater_is_better=True,\n",
    "                                  use_cpu=True, \n",
    "                                  report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10da6ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\AppData\\Local\\Temp\\ipykernel_8180\\185264961.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model,\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args_classifier,\n",
    "                  train_dataset=encoded_audio[\"train\"].with_format(\"torch\").shuffle(seed=42),\n",
    "                  eval_dataset=encoded_audio[\"valid\"].with_format(\"torch\"),\n",
    "                  tokenizer=feature_extractor,\n",
    "                  compute_metrics=compute_metrics, \n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8413bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2710 2:03:35 < 43:55, 0.27 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.504384</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>0.180675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.493431</td>\n",
       "      <td>0.374937</td>\n",
       "      <td>0.273403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.469300</td>\n",
       "      <td>1.498460</td>\n",
       "      <td>0.339098</td>\n",
       "      <td>0.279086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.469300</td>\n",
       "      <td>1.482357</td>\n",
       "      <td>0.344862</td>\n",
       "      <td>0.293124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.288300</td>\n",
       "      <td>1.473760</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>0.305295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.288300</td>\n",
       "      <td>1.443801</td>\n",
       "      <td>0.369424</td>\n",
       "      <td>0.320977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.288300</td>\n",
       "      <td>1.443330</td>\n",
       "      <td>0.381203</td>\n",
       "      <td>0.340281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>1.435370</td>\n",
       "      <td>0.389975</td>\n",
       "      <td>0.354524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.167500</td>\n",
       "      <td>1.421239</td>\n",
       "      <td>0.397243</td>\n",
       "      <td>0.346710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.112700</td>\n",
       "      <td>1.406204</td>\n",
       "      <td>0.397744</td>\n",
       "      <td>0.340190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=1.259444061279297, metrics={'train_runtime': 7417.9462, 'train_samples_per_second': 11.693, 'train_steps_per_second': 0.365, 'total_flos': 7.1163353099088e+17, 'train_loss': 1.259444061279297, 'epoch': 3.6841862609497467})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5987bd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_test = trainer.predict(encoded_audio[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e384061b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.485963225364685,\n",
       " 'test_accuracy': 0.35216976633285646,\n",
       " 'test_f1': 0.28890461462661593,\n",
       " 'test_runtime': 301.4645,\n",
       " 'test_samples_per_second': 13.912,\n",
       " 'test_steps_per_second': 1.741}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466870cc",
   "metadata": {},
   "source": [
    "# Train encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3e2d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_last_n_layers(model, n):\n",
    "    total_layers = len(model.encoder.layers)\n",
    "    for i in range(total_layers - n, total_layers):\n",
    "        for param in model.encoder.layers[i].parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdeecdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_last_n_layers(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bafb10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_encoder = TrainingArguments(output_dir=f\"whisper-tiny-finetuned-rudialect-fixed-speakers-with-encoder-aug\",\n",
    "                                          eval_strategy=\"steps\",\n",
    "                                          save_strategy=\"steps\",\n",
    "                                          eval_steps=300,\n",
    "                                          save_steps=300,\n",
    "                                          learning_rate=1e-5,\n",
    "                                          per_device_train_batch_size=batch_size,\n",
    "                                          gradient_accumulation_steps=4,\n",
    "                                          per_device_eval_batch_size=batch_size,\n",
    "                                          num_train_epochs=5,\n",
    "                                          load_best_model_at_end=True,\n",
    "                                          metric_for_best_model=\"f1\",\n",
    "                                          greater_is_better=True,\n",
    "                                          use_cpu=True, \n",
    "                                          report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e436d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\AppData\\Local\\Temp\\ipykernel_8180\\3655856878.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_encoder = Trainer(model=model,\n"
     ]
    }
   ],
   "source": [
    "trainer_encoder = Trainer(model=model,\n",
    "                          args=training_args_encoder,\n",
    "                          train_dataset=encoded_audio[\"train\"].with_format(\"torch\").shuffle(seed=42),\n",
    "                          eval_dataset=encoded_audio[\"valid\"].with_format(\"torch\"),\n",
    "                          tokenizer=feature_extractor,\n",
    "                          compute_metrics=compute_metrics, \n",
    "                          callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e1c7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2700' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2700/2710 4:00:35 < 00:53, 0.19 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.200441</td>\n",
       "      <td>0.555138</td>\n",
       "      <td>0.511741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.806600</td>\n",
       "      <td>1.179207</td>\n",
       "      <td>0.563659</td>\n",
       "      <td>0.520825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.806600</td>\n",
       "      <td>1.110458</td>\n",
       "      <td>0.607268</td>\n",
       "      <td>0.561113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>1.003150</td>\n",
       "      <td>0.637343</td>\n",
       "      <td>0.597491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>1.045661</td>\n",
       "      <td>0.622306</td>\n",
       "      <td>0.578844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.977330</td>\n",
       "      <td>0.651629</td>\n",
       "      <td>0.612225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.959897</td>\n",
       "      <td>0.658647</td>\n",
       "      <td>0.626309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.933255</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.618487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.944918</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>0.621861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2700, training_loss=0.4644338113290292, metrics={'train_runtime': 14439.7207, 'train_samples_per_second': 6.007, 'train_steps_per_second': 0.188, 'total_flos': 9.6072141173184e+17, 'train_loss': 0.4644338113290292, 'epoch': 4.9737206085753805})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_encoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11e0691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_test = trainer_encoder.predict(encoded_audio[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2890497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.280464768409729,\n",
       " 'test_accuracy': 0.5662851692894612,\n",
       " 'test_f1': 0.5400392163756708,\n",
       " 'test_runtime': 301.7255,\n",
       " 'test_samples_per_second': 13.9,\n",
       " 'test_steps_per_second': 1.74}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "904d009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('/whisper-tiny-finetuned-rudialect-fixed-speakers-with-encoder-aug/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f54bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
