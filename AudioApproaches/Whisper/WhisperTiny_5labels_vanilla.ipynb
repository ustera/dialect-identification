{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115fbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import WhisperFeatureExtractor, set_seed, EarlyStoppingCallback, AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "tqdm.pandas()\n",
    "set_seed(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64367ad8",
   "metadata": {},
   "source": [
    "# Read audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da90d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(path, sr=16000)\n",
    "        return audio\n",
    "    except:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11141516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25806/25806 [24:03<00:00, 17.87it/s]\n"
     ]
    }
   ],
   "source": [
    "manifest = pd.read_excel('manifest_balanced.xlsx')\n",
    "variants = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "manifest = manifest[manifest['Variant'].isin(variants)]\n",
    "manifest = manifest[['path', 'Variant', 'text', 'informant']]\n",
    "manifest['array'] = manifest['path'].progress_apply(read_audio)\n",
    "manifest['sampling_rate'] = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ada32",
   "metadata": {},
   "source": [
    "# Split on train, validation and test (speakers fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4900349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12771"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = manifest[['path', 'Variant', 'array', 'sampling_rate', 'informant']]\n",
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "variants = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "for variant in variants:\n",
    "    speaker_counts = manifest[manifest['Variant']==variant]['informant'].value_counts().to_dict()\n",
    "    total_records = len(manifest[manifest['Variant']==variant]['path'])\n",
    "    train_target = 0.7 * total_records\n",
    "    val_target = 0.165 * total_records\n",
    "    test_target = total_records - train_target - val_target\n",
    "    speaker_ids = list(speaker_counts.keys())\n",
    "    train_speakers, val_speakers, test_speakers = [], [], []\n",
    "    train_sum = val_sum = test_sum = 0\n",
    "    for speaker in speaker_ids:\n",
    "        count = speaker_counts[speaker]\n",
    "        if train_sum + count <= train_target:\n",
    "            train_speakers.append(speaker)\n",
    "            train_sum += count\n",
    "        elif val_sum + count <= val_target:\n",
    "            val_speakers.append(speaker)\n",
    "            val_sum += count\n",
    "        else:\n",
    "            test_speakers.append(speaker)\n",
    "            test_sum += count\n",
    "    train_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(train_speakers))]\n",
    "    valid_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(val_speakers))]\n",
    "    test_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(test_speakers))]\n",
    "    train = pd.concat([train, train_df])\n",
    "    valid = pd.concat([valid, valid_df])\n",
    "    test = pd.concat([test, test_df])\n",
    "train = train[train['array'].str.len()>0]\n",
    "valid = valid[valid['array'].str.len()>0]\n",
    "test = test[test['array'].str.len()>0]\n",
    "try:\n",
    "    del manifest\n",
    "    del train_df\n",
    "    del valid_df\n",
    "    del test_df\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3844031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'Variant': 'label'})\n",
    "valid = valid.rename(columns={'Variant': 'label'})\n",
    "test = test.rename(columns={'Variant': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc418c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'Arkhangelskie': 0, 'Desninskie': 1, 'Donskie': 2, 'Kostromskie': 3, 'Mezhzonalnie': 4, 'Novgorodskie': 5, 'Povolzkie': 6, 'Pskovskie': 7, 'Ryazanskie': 8, 'Seligerskie': 9}\n",
      "id2label: {0: 'Arkhangelskie', 1: 'Desninskie', 2: 'Donskie', 3: 'Kostromskie', 4: 'Mezhzonalnie', 5: 'Novgorodskie', 6: 'Povolzkie', 7: 'Pskovskie', 8: 'Ryazanskie', 9: 'Seligerskie'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = ['Arkhangelskie', 'Desninskie', 'Donskie', 'Kostromskie', 'Mezhzonalnie', 'Novgorodskie', 'Povolzkie',\n",
    "                 'Pskovskie', 'Ryazanskie', 'Seligerskie']\n",
    "label2id = {label: index for index, label in enumerate(unique_labels)}\n",
    "id2label = {index: label for index, label in enumerate(unique_labels)}\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4897ee1",
   "metadata": {},
   "source": [
    "# Configure the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a66213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537bade45d194dc38003b9903f4e465e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/17347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e3943db7e24ff6b9fdc3fb0a089497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7969ae2354db44ed80e626911b111597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'test': Dataset.from_pandas(valid[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'valid': Dataset.from_pandas(test[['array', 'label']]).class_encode_column(\"label\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "311b594c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].features[\"label\"].str2int('Arkhangelskie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc5fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del train\n",
    "    del valid\n",
    "    del test\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a096ea",
   "metadata": {},
   "source": [
    "# Extract features from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0a57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c063f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_features\"] = feature_extractor(batch[\"array\"], sampling_rate=16000, return_tensors='pt').input_features[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532340b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf643a31bf6475c9292c50132714772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76837acbea644cd5be1c42cbb10d2d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f99ca9d86945ca999f4363f614ba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_audio = ds.map(prepare_dataset, remove_columns=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2648dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_audio = encoded_audio.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4acf2f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(names=['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie'], id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_audio['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23ba57",
   "metadata": {},
   "source": [
    "# Define function for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61228741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c0ff8",
   "metadata": {},
   "source": [
    "# Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa00510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at openai/whisper-tiny and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhisperForAudioClassification(\n",
       "  (encoder): WhisperEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (embed_positions): Embedding(1500, 384)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x WhisperEncoderLayer(\n",
       "        (self_attn): WhisperSdpaAttention(\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projector): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"openai/whisper-tiny\", num_labels=num_labels, label2id=label2id, id2label=id2label)\n",
    "device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0ef27",
   "metadata": {},
   "source": [
    "# Set hyperparameters and train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2655c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(output_dir=f\"whisper-tiny-finetuned-rudialect-fixed-speakers-trainallmodel\",\n",
    "                                  eval_strategy=\"steps\",\n",
    "                                  save_strategy=\"steps\",\n",
    "                                  eval_steps=300,\n",
    "                                  save_steps=300,\n",
    "                                  learning_rate=1e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  gradient_accumulation_steps=4,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  num_train_epochs=5,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  greater_is_better=True,\n",
    "                                  use_cpu=True, \n",
    "                                  report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e146852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\AppData\\Local\\Temp\\ipykernel_12340\\543912420.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model,\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=encoded_audio[\"train\"].with_format(\"torch\"),\n",
    "                  eval_dataset=encoded_audio[\"valid\"].with_format(\"torch\"),\n",
    "                  tokenizer=feature_extractor,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a69deb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 6:03:00, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.055063</td>\n",
       "      <td>0.636842</td>\n",
       "      <td>0.535020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.974400</td>\n",
       "      <td>1.007700</td>\n",
       "      <td>0.680201</td>\n",
       "      <td>0.614667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.974400</td>\n",
       "      <td>0.997298</td>\n",
       "      <td>0.707018</td>\n",
       "      <td>0.628387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>1.073791</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>1.151659</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.638888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>1.234834</td>\n",
       "      <td>0.710025</td>\n",
       "      <td>0.653389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>1.368924</td>\n",
       "      <td>0.704511</td>\n",
       "      <td>0.641053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>1.323351</td>\n",
       "      <td>0.729073</td>\n",
       "      <td>0.671560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.430704</td>\n",
       "      <td>0.717043</td>\n",
       "      <td>0.656992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2710, training_loss=0.28739759121433833, metrics={'train_runtime': 21787.6595, 'train_samples_per_second': 3.981, 'train_steps_per_second': 0.124, 'total_flos': 9.6444467489664e+17, 'train_loss': 0.28739759121433833, 'epoch': 4.992162286768096})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ca30f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_test = trainer.predict(encoded_audio[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a4ec98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.4508670568466187,\n",
       " 'test_accuracy': 0.6852646638054364,\n",
       " 'test_f1': 0.6265265282734863,\n",
       " 'test_runtime': 297.763,\n",
       " 'test_samples_per_second': 14.085,\n",
       " 'test_steps_per_second': 1.763}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b822e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('/whisper-tiny-finetuned-rudialect-fixed-speakers-trainallmodel/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732da5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
