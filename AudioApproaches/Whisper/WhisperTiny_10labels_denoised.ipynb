{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115fbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import WhisperFeatureExtractor, set_seed\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import noisereduce as nr\n",
    "tqdm.pandas()\n",
    "set_seed(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f7fdd",
   "metadata": {},
   "source": [
    "# Read and denoise audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da90d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(path, sr=16000)\n",
    "        return audio\n",
    "    except:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f06e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denose_audio(audio):\n",
    "    return nr.reduce_noise(y=audio, sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11141516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 55657/55657 [1:15:43<00:00, 12.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 55657/55657 [49:21<00:00, 18.79it/s]\n"
     ]
    }
   ],
   "source": [
    "manifest = pd.read_excel('manifest_balanced.xlsx')\n",
    "manifest = manifest[['path', 'Variant', 'text']]\n",
    "manifest['audio'] = manifest['path'].progress_apply(read_audio)\n",
    "manifest['sampling_rate'] = 16000\n",
    "manifest['array'] = manifest['audio'].progress_apply(denose_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6904e",
   "metadata": {},
   "source": [
    "# Split on train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4900349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8760"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = manifest[['path', 'Variant', 'array', 'sampling_rate']]\n",
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "for variant in list(manifest['Variant'].unique()):\n",
    "    train_df, valid_test_df = train_test_split(manifest[manifest['Variant']==variant], test_size=0.3, random_state=55)\n",
    "    valid_df, test_df = train_test_split(valid_test_df, test_size=0.5, random_state=55)\n",
    "    train = pd.concat([train, train_df])\n",
    "    valid = pd.concat([valid, valid_df])\n",
    "    test = pd.concat([test, test_df])\n",
    "train = train[train['array'].str.len()>0]\n",
    "valid = valid[valid['array'].str.len()>0]\n",
    "test = test[test['array'].str.len()>0]\n",
    "try:\n",
    "    del manifest\n",
    "    del train_df\n",
    "    del valid_test_df\n",
    "    del valid_df\n",
    "    del test_df\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3844031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'Variant': 'label'})\n",
    "valid = valid.rename(columns={'Variant': 'label'})\n",
    "test = test.rename(columns={'Variant': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a370d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'Arkhangelskie': 0, 'Desninskie': 1, 'Donskie': 2, 'Kostromskie': 3, 'Mezhzonalnie': 4, 'Novgorodskie': 5, 'Povolzkie': 6, 'Pskovskie': 7, 'Ryazanskie': 8, 'Seligerskie': 9}\n",
      "id2label: {0: 'Arkhangelskie', 1: 'Desninskie', 2: 'Donskie', 3: 'Kostromskie', 4: 'Mezhzonalnie', 5: 'Novgorodskie', 6: 'Povolzkie', 7: 'Pskovskie', 8: 'Ryazanskie', 9: 'Seligerskie'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = ['Arkhangelskie', 'Desninskie', 'Donskie', 'Kostromskie', 'Mezhzonalnie', 'Novgorodskie', 'Povolzkie',\n",
    "                 'Pskovskie', 'Ryazanskie', 'Seligerskie']\n",
    "label2id = {label: index for index, label in enumerate(unique_labels)}\n",
    "id2label = {index: label for index, label in enumerate(unique_labels)}\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9219dd",
   "metadata": {},
   "source": [
    "# Configure the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a66213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e06dc30b81842c992b84eaa92d1faef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/38022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03acfb1b63da4b39bf4aeed4449b6066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/8129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4a39bffc88419dae946da8235054be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/8152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'test': Dataset.from_pandas(valid[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'valid': Dataset.from_pandas(test[['array', 'label']]).class_encode_column(\"label\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc5fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del train\n",
    "    del valid\n",
    "    del test\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247933cd",
   "metadata": {},
   "source": [
    "# Extract features from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0a57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c063f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_features\"] = feature_extractor(batch[\"array\"], sampling_rate=16000, return_tensors='pt').input_features[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532340b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4eaa03e594467e974b66f453daf519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e52b636d7034998ae116252362e93b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6db89bb649543959144161902df5a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_audio = ds.map(prepare_dataset, remove_columns=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2648dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_audio = encoded_audio.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4acf2f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(names=['Arkhangelskie', 'Desninskie', 'Donskie', 'Kostromskie', 'Mezhzonalnie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie', 'Seligerskie'], id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_audio['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b39b2e",
   "metadata": {},
   "source": [
    "# Define function for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61228741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefc8fe",
   "metadata": {},
   "source": [
    "# Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa00510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at openai/whisper-tiny and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhisperForAudioClassification(\n",
       "  (encoder): WhisperEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (embed_positions): Embedding(1500, 384)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x WhisperEncoderLayer(\n",
       "        (self_attn): WhisperSdpaAttention(\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projector): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"openai/whisper-tiny\", num_labels=num_labels, label2id=label2id, id2label=id2label)\n",
    "device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80236f92",
   "metadata": {},
   "source": [
    "# Set hyperparameters and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2655c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(output_dir=f\"whisper-tiny-finetuned-rudialect-denoised\",\n",
    "                                  eval_strategy =\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  learning_rate=3e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  gradient_accumulation_steps=4,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  num_train_epochs=5,\n",
    "                                  warmup_ratio=0.1,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\", \n",
    "                                  use_cpu=True, \n",
    "                                  report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e146852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\AppData\\Local\\Temp\\ipykernel_16960\\3244443662.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model,\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=encoded_audio[\"train\"].shuffle(seed=42).with_format(\"torch\"),\n",
    "                  eval_dataset=encoded_audio[\"valid\"].with_format(\"torch\"),\n",
    "                  tokenizer=feature_extractor,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a69deb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5940' max='5940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5940/5940 12:19:59, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>0.438485</td>\n",
       "      <td>0.862856</td>\n",
       "      <td>0.849874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.239304</td>\n",
       "      <td>0.927380</td>\n",
       "      <td>0.920151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.199755</td>\n",
       "      <td>0.942100</td>\n",
       "      <td>0.936298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.166854</td>\n",
       "      <td>0.962954</td>\n",
       "      <td>0.959999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5940, training_loss=0.3274283163475268, metrics={'train_runtime': 44406.4199, 'train_samples_per_second': 4.281, 'train_steps_per_second': 0.134, 'total_flos': 2.11562216015616e+18, 'train_loss': 0.3274283163475268, 'epoch': 4.996423311592678})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ca30f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_test = trainer.predict(encoded_audio[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a4ec98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.1427411437034607,\n",
       " 'test_accuracy': 0.9689998769836389,\n",
       " 'test_f1': 0.9665994429635025,\n",
       " 'test_runtime': 582.2955,\n",
       " 'test_samples_per_second': 13.96,\n",
       " 'test_steps_per_second': 1.747}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a52a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('/whisper-tiny-finetuned-rudialect-denoised/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5914ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
