{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dacc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import WhisperFeatureExtractor, set_seed, AutoModelForAudioClassification, TrainingArguments, Trainer, WhisperConfig, EarlyStoppingCallback\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "tqdm.pandas()\n",
    "set_seed(55)\n",
    "np.random.seed(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e26ce",
   "metadata": {},
   "source": [
    "# Read audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(path, sr=16000)\n",
    "        return audio\n",
    "    except:\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fe45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25806/25806 [23:55<00:00, 17.98it/s]\n"
     ]
    }
   ],
   "source": [
    "manifest = pd.read_excel('manifest_balanced.xlsx')\n",
    "variants = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "manifest = manifest[manifest['Variant'].isin(variants)]\n",
    "manifest = manifest[['path', 'Variant', 'text', 'informant']]\n",
    "manifest['array'] = manifest['path'].progress_apply(read_audio)\n",
    "manifest['sampling_rate'] = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50453e4f",
   "metadata": {},
   "source": [
    "# Split on train, validation and test (speakers fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daeaf9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12705"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = manifest[['path', 'Variant', 'array', 'sampling_rate', 'informant']]\n",
    "train = pd.DataFrame()\n",
    "valid = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "variants = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "for variant in variants:\n",
    "    speaker_counts = manifest[manifest['Variant']==variant]['informant'].value_counts().to_dict()\n",
    "    total_records = len(manifest[manifest['Variant']==variant]['path'])\n",
    "    train_target = 0.7 * total_records\n",
    "    val_target = 0.165 * total_records\n",
    "    test_target = total_records - train_target - val_target\n",
    "    speaker_ids = list(speaker_counts.keys())\n",
    "    train_speakers, val_speakers, test_speakers = [], [], []\n",
    "    train_sum = val_sum = test_sum = 0\n",
    "    for speaker in speaker_ids:\n",
    "        count = speaker_counts[speaker]\n",
    "        if train_sum + count <= train_target:\n",
    "            train_speakers.append(speaker)\n",
    "            train_sum += count\n",
    "        elif val_sum + count <= val_target:\n",
    "            val_speakers.append(speaker)\n",
    "            val_sum += count\n",
    "        else:\n",
    "            test_speakers.append(speaker)\n",
    "            test_sum += count\n",
    "    train_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(train_speakers))]\n",
    "    valid_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(val_speakers))]\n",
    "    test_df = manifest[(manifest['Variant']==variant)&(manifest['informant'].isin(test_speakers))]\n",
    "    train = pd.concat([train, train_df])\n",
    "    valid = pd.concat([valid, valid_df])\n",
    "    test = pd.concat([test, test_df])\n",
    "train = train[train['array'].str.len()>0]\n",
    "valid = valid[valid['array'].str.len()>0]\n",
    "test = test[test['array'].str.len()>0]\n",
    "try:\n",
    "    del manifest\n",
    "    del train_df\n",
    "    del valid_df\n",
    "    del test_df\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367c65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'Variant': 'label'})\n",
    "valid = valid.rename(columns={'Variant': 'label'})\n",
    "test = test.rename(columns={'Variant': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7e9e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'Arkhangelskie': 0, 'Novgorodskie': 1, 'Povolzkie': 2, 'Pskovskie': 3, 'Ryazanskie': 4}\n",
      "id2label: {0: 'Arkhangelskie', 1: 'Novgorodskie', 2: 'Povolzkie', 3: 'Pskovskie', 4: 'Ryazanskie'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = ['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie']\n",
    "label2id = {label: index for index, label in enumerate(unique_labels)}\n",
    "id2label = {index: label for index, label in enumerate(unique_labels)}\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a31d69e",
   "metadata": {},
   "source": [
    "# Configure the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a25032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69baf7312cc1498ba70aa7a19a26653f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/17347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca35a652bc3843b4bf395186373e1f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bb2f51e51343399ac3e861588c85c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'test': Dataset.from_pandas(valid[['array', 'label']]).class_encode_column(\"label\"),\n",
    "    'valid': Dataset.from_pandas(test[['array', 'label']]).class_encode_column(\"label\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0f0f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].features[\"label\"].str2int('Arkhangelskie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bb12c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del train\n",
    "    del valid\n",
    "    del test\n",
    "except:\n",
    "    pass\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b569a",
   "metadata": {},
   "source": [
    "# Extract features from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd36a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "636f9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_features\"] = feature_extractor(batch[\"array\"], sampling_rate=16000, return_tensors='pt').input_features[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21ec93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce7cc0866d643db918a75ab196ea9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c845162e7d4abb9c7477ce01fb0ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8bad43b91c42f2bd23e5f98fd2d5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_audio = ds.map(prepare_dataset, remove_columns=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5278c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_audio = encoded_audio.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a146b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(names=['Arkhangelskie', 'Novgorodskie', 'Povolzkie', 'Pskovskie', 'Ryazanskie'], id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_audio['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc1405",
   "metadata": {},
   "source": [
    "# Define function for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a17bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc7919",
   "metadata": {},
   "source": [
    "# Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ae8308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at openai/whisper-tiny and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhisperForAudioClassification(\n",
       "  (encoder): WhisperEncoder(\n",
       "    (conv1): Conv1d(80, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(384, 384, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (embed_positions): Embedding(1500, 384)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x WhisperEncoderLayer(\n",
       "        (self_attn): WhisperSdpaAttention(\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projector): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (classifier): Linear(in_features=256, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(id2label)\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-tiny\", num_labels=num_labels, label2id=label2id, id2label=id2label)\n",
    "config.classifier_dropout = 0.3\n",
    "model = AutoModelForAudioClassification.from_pretrained(\"openai/whisper-tiny\", config=config)\n",
    "device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b9a26",
   "metadata": {},
   "source": [
    "# Train classifier only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ed57c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_encoder(model):\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74f871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_encoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d91bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "training_args_classifier = TrainingArguments(output_dir=f\"whisper-tiny-finetuned-rudialect-fixed-speakers-classifier-only\",\n",
    "                                  eval_strategy =\"steps\",\n",
    "                                  save_strategy=\"steps\",\n",
    "                                  learning_rate=1e-4,\n",
    "                                  eval_steps=200,\n",
    "                                  save_steps=200,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  gradient_accumulation_steps=4,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  num_train_epochs=5,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  greater_is_better=True,\n",
    "                                  use_cpu=True, \n",
    "                                  report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10da6ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\AppData\\Local\\Temp\\ipykernel_14080\\185264961.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model,\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args_classifier,\n",
    "                  train_dataset=encoded_audio[\"train\"].with_format(\"torch\").shuffle(seed=42),\n",
    "                  eval_dataset=encoded_audio[\"valid\"].with_format(\"torch\"),\n",
    "                  tokenizer=feature_extractor,\n",
    "                  compute_metrics=compute_metrics, \n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8413bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2710 2:01:49 < 43:17, 0.27 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.516844</td>\n",
       "      <td>0.326566</td>\n",
       "      <td>0.172010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.505464</td>\n",
       "      <td>0.332331</td>\n",
       "      <td>0.236420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.493700</td>\n",
       "      <td>1.505873</td>\n",
       "      <td>0.316541</td>\n",
       "      <td>0.255721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.493700</td>\n",
       "      <td>1.482200</td>\n",
       "      <td>0.348622</td>\n",
       "      <td>0.291816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.377700</td>\n",
       "      <td>1.480709</td>\n",
       "      <td>0.356140</td>\n",
       "      <td>0.300080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.377700</td>\n",
       "      <td>1.446230</td>\n",
       "      <td>0.378446</td>\n",
       "      <td>0.321424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.377700</td>\n",
       "      <td>1.455946</td>\n",
       "      <td>0.384211</td>\n",
       "      <td>0.342372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.299300</td>\n",
       "      <td>1.443962</td>\n",
       "      <td>0.395489</td>\n",
       "      <td>0.357523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.299300</td>\n",
       "      <td>1.425205</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.355646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.248200</td>\n",
       "      <td>1.404091</td>\n",
       "      <td>0.412531</td>\n",
       "      <td>0.354456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=1.3547186889648437, metrics={'train_runtime': 7311.4684, 'train_samples_per_second': 11.863, 'train_steps_per_second': 0.371, 'total_flos': 7.1163353099088e+17, 'train_loss': 1.3547186889648437, 'epoch': 3.6841862609497467})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5987bd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_test = trainer.predict(encoded_audio[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e384061b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.4064407348632812,\n",
       " 'test_accuracy': 0.42727706247019553,\n",
       " 'test_f1': 0.3649119947207621,\n",
       " 'test_runtime': 295.2187,\n",
       " 'test_samples_per_second': 14.206,\n",
       " 'test_steps_per_second': 1.778}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466870cc",
   "metadata": {},
   "source": [
    "# Train encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3e2d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_last_n_layers(model, n):\n",
    "    total_layers = len(model.encoder.layers)\n",
    "    for i in range(total_layers - n, total_layers):\n",
    "        for param in model.encoder.layers[i].parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdeecdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_last_n_layers(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bafb10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_encoder = TrainingArguments(output_dir=f\"whisper-tiny-finetuned-rudialect-fixed-speakers-with-encoder\",\n",
    "                                          eval_strategy=\"steps\",\n",
    "                                          save_strategy=\"steps\",\n",
    "                                          eval_steps=300,\n",
    "                                          save_steps=300,\n",
    "                                          learning_rate=1e-5,\n",
    "                                          per_device_train_batch_size=batch_size,\n",
    "                                          gradient_accumulation_steps=4,\n",
    "                                          per_device_eval_batch_size=batch_size,\n",
    "                                          num_train_epochs=5,\n",
    "                                          load_best_model_at_end=True,\n",
    "                                          metric_for_best_model=\"f1\",\n",
    "                                          greater_is_better=True,\n",
    "                                          use_cpu=True, \n",
    "                                          report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e436d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\AppData\\Local\\Temp\\ipykernel_14080\\3655856878.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_encoder = Trainer(model=model,\n"
     ]
    }
   ],
   "source": [
    "trainer_encoder = Trainer(model=model,\n",
    "                          args=training_args_encoder,\n",
    "                          train_dataset=encoded_audio[\"train\"].with_format(\"torch\").shuffle(seed=42),\n",
    "                          eval_dataset=encoded_audio[\"valid\"].with_format(\"torch\"),\n",
    "                          tokenizer=feature_extractor,\n",
    "                          compute_metrics=compute_metrics, \n",
    "                          callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e1c7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 3:59:29, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.134780</td>\n",
       "      <td>0.574185</td>\n",
       "      <td>0.521195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.929700</td>\n",
       "      <td>1.002830</td>\n",
       "      <td>0.634586</td>\n",
       "      <td>0.578388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.929700</td>\n",
       "      <td>0.981909</td>\n",
       "      <td>0.649875</td>\n",
       "      <td>0.600095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.938433</td>\n",
       "      <td>0.653383</td>\n",
       "      <td>0.595468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.955443</td>\n",
       "      <td>0.667419</td>\n",
       "      <td>0.622709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.907219</td>\n",
       "      <td>0.683459</td>\n",
       "      <td>0.632552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.903619</td>\n",
       "      <td>0.695990</td>\n",
       "      <td>0.645265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.357800</td>\n",
       "      <td>0.907136</td>\n",
       "      <td>0.692732</td>\n",
       "      <td>0.646820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.685213</td>\n",
       "      <td>0.635663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n",
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2710, training_loss=0.5001308933835188, metrics={'train_runtime': 14373.8735, 'train_samples_per_second': 6.034, 'train_steps_per_second': 0.189, 'total_flos': 9.6428442285504e+17, 'train_loss': 0.5001308933835188, 'epoch': 4.992162286768096})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_encoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11e0691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_test = trainer_encoder.predict(encoded_audio[\"test\"].with_format(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2890497a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.3440494537353516,\n",
       " 'test_accuracy': 0.5815450643776824,\n",
       " 'test_f1': 0.5466198287395072,\n",
       " 'test_runtime': 294.8818,\n",
       " 'test_samples_per_second': 14.223,\n",
       " 'test_steps_per_second': 1.78}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "904d009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('/whisper-tiny-finetuned-rudialect-fixed-speakers-with-encoder/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f54bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
