{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7442b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "import warnings\n",
    "import statistics\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25540922",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4905e",
   "metadata": {},
   "source": [
    "Import all data, where mentioned corpus, path to audio, transcription, duration of audio, informant code, number of tokens in transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9565c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('manifest.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915f070",
   "metadata": {},
   "source": [
    "Let's set a threshold value for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df940c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_minutes_per_corpus = {\n",
    "    'Keba': 63, \n",
    "    'Dvina': 63, \n",
    "    'Pinega': 63, \n",
    "    'Pyoza': 63, \n",
    "    'Tserkovnoe': 63, \n",
    "    'Vaduga': 63, \n",
    "    'Veegora': 63, \n",
    "    'Manturovo': 441, \n",
    "    'LukhTeza': 441, \n",
    "    'Novgorod': 441,\n",
    "    'Opochka': 147, \n",
    "    'Pyatiusovo': 147,\n",
    "    'Shetnevo': 147,\n",
    "    'Luzhnikovo': 441, \n",
    "    'Nekhochi': 441, \n",
    "    'Rogovatka': 441, \n",
    "    'Malinino': 147, \n",
    "    'Mikhaylov': 147, \n",
    "    'Popovka': 147,\n",
    "    'Don': 441\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c28210f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1      int64\n",
       "Unnamed: 0        int64\n",
       "corpus           object\n",
       "path             object\n",
       "text             object\n",
       "duration        float64\n",
       "informant        object\n",
       "tokens_len      float64\n",
       "duration_min    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration_min'] = df['duration']/60\n",
    "df.astype({'tokens_len': np.float64}).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f69ce",
   "metadata": {},
   "source": [
    "# Prepare functions for creating subcorpuses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fadc7e",
   "metadata": {},
   "source": [
    "We define a function for selecting an element to add to the dataset. We randomly select utterances from each informant in the corpus. If the phrase has already been selected to the dataset, it is flagged and is not selected again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288d5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_element(corpus, limit, random_state):\n",
    "    global amount_of_minutes_per_corpus, df\n",
    "    \n",
    "    df_filtered = df[(df['corpus']==corpus)]\n",
    "    df_filtered['AlreadyChosen'] = 0\n",
    "    speakers = df_filtered['informant'].unique()\n",
    "    df_result = pd.DataFrame(columns=df.columns)\n",
    "    last_size = -1\n",
    "    \n",
    "    while round(df_result[df_result['corpus']==corpus]['duration_min'].sum())-0.3 < limit:\n",
    "        for speaker in speakers:\n",
    "            df_filtered2 = df_filtered[(df_filtered['informant'] == speaker)&(df_filtered['AlreadyChosen'] == 0)]\n",
    "            if df_filtered2.size>0:\n",
    "                row = df_filtered2.sample(n=1, random_state=random_state)\n",
    "                df_filtered.loc[row.index, 'AlreadyChosen'] = 1\n",
    "                already_minutes = df_result[df_result['corpus']==corpus]['duration_min'].sum()\n",
    "                if already_minutes + row['duration_min'].sum() < limit:\n",
    "                    df_result = pd.concat([df_result, row])\n",
    "        if last_size == df_result.size:\n",
    "            return df_result\n",
    "        else:\n",
    "            last_size = df_result.size\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e79b6",
   "metadata": {},
   "source": [
    "In this function, we take into account the distributions that result from selecting a random seed using the Mann-Whitney test. Here we use test for audio durations and number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08506397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_distributions(corpus, limit):\n",
    "    d = []\n",
    "    for i in tqdm(range(200, 500)):\n",
    "        res = get_random_element(corpus, limit, i)\n",
    "        U_length_audio, p_length_audio = mannwhitneyu(res['duration_min'].astype(np.float64), \n",
    "                                                      df[df['corpus']== corpus]['duration_min'].astype(np.float64))\n",
    "        U_length_sent, p_length_sent = mannwhitneyu(res['tokens_len'].astype(np.float64), \n",
    "                                                    df[df['corpus']== corpus]['tokens_len'].astype(np.float64))\n",
    "        \n",
    "        if p_length_audio>0.05 and p_length_sent>0.05:\n",
    "            d.append([corpus, i, 1, 1, sum(res['duration_min']), sum(res['tokens_len'])])\n",
    "        elif p_length_audio>0.05 and p_length_sent<=0.05:\n",
    "            d.append([corpus, i, 1, 0, sum(res['duration_min']), sum(res['tokens_len'])])\n",
    "        elif p_length_audio<=0.05 and p_length_sent>0.05:\n",
    "            d.append([corpus, i, 0, 1, sum(res['duration_min']), sum(res['tokens_len'])])\n",
    "        else:\n",
    "            d.append([corpus, i, 0, 0, sum(res['duration_min']), sum(res['tokens_len'])])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60107d84",
   "metadata": {},
   "source": [
    "# Find the best random state where most of the subcorpuses will have similar distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5926e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 20/20 [6:28:49<00:00, 1166.48s/it]\n"
     ]
    }
   ],
   "source": [
    "all_stats_res2 = []\n",
    "df['AlreadyChosen'] = 0\n",
    "for corpus, limit in tqdm(amount_of_minutes_per_corpus.items()):\n",
    "    corpus_res = count_distributions(corpus, limit)\n",
    "    all_stats_res2.append(corpus_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b184ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "all_stats_res_2 = flatten(all_stats_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "294f6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_stats_res = pd.DataFrame(all_stats_res_2, columns=['Corpus', 'Random_state', 'P-value greater than 0.5 (audio)', \n",
    "                                                          'P-value greater than 0.5 (text)', 'Sum audio', 'Sum tokens'])\n",
    "df_all_stats_res.to_excel('сorpus_statistics_by_random_state.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6666b9",
   "metadata": {},
   "source": [
    "# Count tokens for each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0294db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_random_states = pd.read_excel('corpus_statistics_by_random_state_all.xlsx')\n",
    "variants = list(all_random_states['Variant'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c9bfd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entries(corpus, limit, random_state):\n",
    "    res = get_random_element(corpus, limit, random_state)\n",
    "    return res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "84627a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 3453/3453 [7:50:28<00:00,  8.17s/it]\n"
     ]
    }
   ],
   "source": [
    "all_random_states['entries'] = all_random_states.progress_apply(lambda x: count_entries(x['Corpus'], \n",
    "                                                                                        amount_of_minutes_per_corpus[x['Corpus']], \n",
    "                                                                                        x['Random_state']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f0af26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_random_states.to_excel('corpus_statistics_by_random_state_all_entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc78b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56172.142857142855"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = all_random_states.groupby('Variant')['Sum tokens'].agg(['max']).to_dict()['max']\n",
    "median.pop(\"Arhangelsk\")\n",
    "median.pop(\"pskovskie\")\n",
    "median.pop(\"ryazan\")\n",
    "statistics.mean(list(median.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a2fbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Desna': 58007,\n",
       " 'Kostroma': 64281,\n",
       " 'Povolzie': 57290,\n",
       " 'donskie': 56434,\n",
       " 'mezhzon': 47455,\n",
       " 'novgorod': 55929,\n",
       " 'seliger': 53809}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1844301",
   "metadata": {},
   "source": [
    "# Find the optimal amount of tokens for variant: we are trying to make proportionate volumes for each group of dialects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d66406",
   "metadata": {},
   "source": [
    "Previously, we calculated the volume of tokens for each group of dialects depending on the random state. Now we are trying to find the closest volume to the median (which was calculated for all possible groups). If the corpus volume is closest to the median, we choose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "228419b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 2856.67it/s]\n"
     ]
    }
   ],
   "source": [
    "corpora = list(all_random_states['Corpus'].unique())\n",
    "choosed_data_all = []\n",
    "for corpus in tqdm(corpora):\n",
    "    corpus_data = all_random_states[all_random_states['Corpus']==corpus].values.tolist()\n",
    "    choose = corpus_data[0]\n",
    "    min_delta = 100000\n",
    "    for i in range(len(corpus_data)):\n",
    "        if abs(corpus_data[i][6]-56172.142857142855) < min_delta:\n",
    "            choose = corpus_data[i]\n",
    "            min_delta = abs(corpus_data[i][6]-56172.142857142855)\n",
    "    choosed_data_all.append(choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1110557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Sum tokens</th>\n",
       "      <th>Sum audio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arhangelsk</th>\n",
       "      <td>57160</td>\n",
       "      <td>440.884767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desna</th>\n",
       "      <td>57700</td>\n",
       "      <td>440.932917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kostroma</th>\n",
       "      <td>63941</td>\n",
       "      <td>440.970433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Povolzie</th>\n",
       "      <td>56715</td>\n",
       "      <td>440.994333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donskie</th>\n",
       "      <td>56174</td>\n",
       "      <td>440.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mezhzon</th>\n",
       "      <td>47455</td>\n",
       "      <td>440.985933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>novgorod</th>\n",
       "      <td>55929</td>\n",
       "      <td>440.989550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pskovskie</th>\n",
       "      <td>59809</td>\n",
       "      <td>440.934667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryazan</th>\n",
       "      <td>56529</td>\n",
       "      <td>440.949900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seliger</th>\n",
       "      <td>53809</td>\n",
       "      <td>440.997933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sum tokens   Sum audio\n",
       "                  sum         sum\n",
       "Variant                          \n",
       "Arhangelsk      57160  440.884767\n",
       "Desna           57700  440.932917\n",
       "Kostroma        63941  440.970433\n",
       "Povolzie        56715  440.994333\n",
       "donskie         56174  440.991900\n",
       "mezhzon         47455  440.985933\n",
       "novgorod        55929  440.989550\n",
       "pskovskie       59809  440.934667\n",
       "ryazan          56529  440.949900\n",
       "seliger         53809  440.997933"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state_result = pd.DataFrame(choosed_data_all, columns=['Corpus', 'Variant', 'Random_state', \n",
    "                                                              'P-value greater than 0.5 (audio)', \n",
    "                                                              'P-value greater than 0.5 (text)', 'Sum audio', 'Sum tokens'])\n",
    "random_state_result.groupby('Variant')['Sum tokens', 'Sum audio'].agg(['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c24ac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3971.4174660944423"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = random_state_result.groupby('Variant')['Sum tokens'].agg(['sum']).to_dict()['sum']\n",
    "np.std(list(res.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d9e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_state = random_state_result.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e4458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [02:22<00:00,  7.13s/it]\n"
     ]
    }
   ],
   "source": [
    "df['AlreadyChosen'] = 0\n",
    "df_balanced = pd.DataFrame(columns=df.columns)\n",
    "for item in tqdm(res_state):\n",
    "    subcorpus = get_random_element(item['Corpus'], amount_of_minutes_per_corpus[item['Corpus']], item['Random_state'])\n",
    "    df_balanced = pd.concat([df_balanced, subcorpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a665f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.to_excel('manifest_balanced.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb4827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
